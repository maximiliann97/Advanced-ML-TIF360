{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxim\\OneDrive\\Dokument\\Chalmers\\Advanced machine learning with neural networks\\hwc_venv\\Lib\\site-packages\\deeptrack\\backend\\_config.py:11: UserWarning: cupy not installed. GPU-accelerated simulations will not be possible\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxim\\OneDrive\\Dokument\\Chalmers\\Advanced machine learning with neural networks\\hwc_venv\\Lib\\site-packages\\deeptrack\\backend\\_config.py:25: UserWarning: cupy not installed, CPU acceleration not enabled\n",
      "  warnings.warn(\"cupy not installed, CPU acceleration not enabled\")\n",
      "C:\\Users\\maxim\\OneDrive\\Dokument\\Chalmers\\Advanced machine learning with neural networks\\hwc_venv\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxim\\OneDrive\\Dokument\\Chalmers\\Advanced machine learning with neural networks\\hwc_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import deeptrack as dt\n",
    "import numpy as np\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "sequence_length = 10  # Number of frames per sequence\n",
    "MIN_SIZE = 0.5e-6\n",
    "MAX_SIZE = 1.5e-6\n",
    "MAX_VEL = 10  # Maximum velocity. The higher the trickier!\n",
    "MAX_PARTICLES = 3  # Max number of particles in each sequence. The higher the trickier!\n",
    "\n",
    "# Defining properties of the particles\n",
    "particle = dt.Sphere(\n",
    "    intensity=lambda: 10 + 10 * np.random.rand(),\n",
    "    radius=lambda: MIN_SIZE + np.random.rand() * (MAX_SIZE - MIN_SIZE),\n",
    "    position=lambda: IMAGE_SIZE * np.random.rand(2),\n",
    "    vel=lambda: MAX_VEL * np.random.rand(2),\n",
    "    position_unit=\"pixel\",\n",
    ")\n",
    "\n",
    "# Defining an update rule for the particle position\n",
    "def get_position(previous_value, vel):\n",
    "\n",
    "    newv = previous_value + vel\n",
    "    for i in range(2):\n",
    "        if newv[i] > 63:\n",
    "            newv[i] = 63 - np.abs(newv[i] - 63)\n",
    "            vel[i] = -vel[i]\n",
    "        elif newv[i] < 0:\n",
    "            newv[i] = np.abs(newv[i])\n",
    "            vel[i] = -vel[i]\n",
    "    return newv\n",
    "\n",
    "\n",
    "particle = dt.Sequential(particle, position=get_position)\n",
    "\n",
    "# Defining properties of the microscope\n",
    "optics = dt.Fluorescence(\n",
    "    NA=1,\n",
    "    output_region=(0, 0, IMAGE_SIZE, IMAGE_SIZE),\n",
    "    magnification=10,\n",
    "    resolution=(1e-6, 1e-6, 1e-6),\n",
    "    wavelength=633e-9,\n",
    ")\n",
    "\n",
    "# Combining everything into a dataset.\n",
    "# Note that the sequences are flipped in different directions, so that each unique sequence defines\n",
    "# in fact 8 sequences flipped in different directions, to speed up data generation\n",
    "sequential_images = dt.Sequence(\n",
    "    optics(particle ** (lambda: 1 + np.random.randint(MAX_PARTICLES))),\n",
    "    sequence_length=sequence_length,\n",
    ")\n",
    "dataset = sequential_images >> dt.FlipUD() >> dt.FlipDiagonal() >> dt.FlipLR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, layers, losses\n",
    "import tensorflow as tf\n",
    "Layer=keras.layers.Layer\n",
    "Conv2D=keras.layers.Conv2D\n",
    "MaxPool2D=keras.layers.MaxPooling2D\n",
    "Dense=keras.layers.Dense\n",
    "Flatten=keras.layers.Flatten\n",
    "Reshape=keras.layers.Reshape\n",
    "\n",
    "class Time2Vector(Layer): #Time embedding layer\n",
    "    def __init__(self, seq_len, **kwargs):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.weights_linear = self.add_weight(name='weight_linear',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.bias_linear = self.add_weight(name='bias_linear',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.math.reduce_mean(x[:,:,:], axis=-1) # Convert (batch, seq_len, 5) to (batch, seq_len)\n",
    "        time_linear = self.weights_linear * x + self.bias_linear\n",
    "        time_linear = tf.expand_dims(time_linear, axis=-1) # (batch, seq_len, 1)\n",
    "\n",
    "        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "        time_periodic = tf.expand_dims(time_periodic, axis=-1) # (batch, seq_len, 1)\n",
    "        return tf.concat([time_linear, time_periodic], axis=-1) # (batch, seq_len, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttention(Layer): #Attention layer\n",
    "    def __init__(self, d_k, d_v):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.query = Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "        self.key = Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "        self.value = Dense(self.d_v, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "        q = self.query(inputs[0])\n",
    "        k = self.key(inputs[1])\n",
    "\n",
    "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
    "        attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
    "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
    "\n",
    "        v = self.value(inputs[2])\n",
    "        attn_out = tf.matmul(attn_weights, v)\n",
    "        return attn_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAttention(Layer):\n",
    "    def __init__(self, d_k, d_v, h, d_f):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.heads = h\n",
    "        self.d_f = d_f\n",
    "        self.attn_layers = []\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        for head in range(self.heads):\n",
    "            self.attn_layers.append(SingleAttention(self.d_k, self.d_v))\n",
    "        self.dense = Dense(self.d_f, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "    \n",
    "    def call(self, input):\n",
    "        attention = [self.attn_layers[i](input) for i in range(self.heads)]\n",
    "        conc_attention = tf.concat(attention, axis=1)\n",
    "        mlp = self.linear(conc_attention)\n",
    "        return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, d_k, d_v, h, d_f, d_filt):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.heads = h\n",
    "        self.d_f = d_f\n",
    "        self.d_filt = d_filt\n",
    "    def build(self, input_shape):\n",
    "        self.multi_head = MultiAttention(self.d_k, self.d_v, self.h, self_d_f)\n",
    "        self.dropout = Dropout(rate=0.2)\n",
    "        self.norm1 = LayerNormalization(epsilon=0.0001)\n",
    "        self.conv1 = Conv2D(filters=self.d_f, kernel_size=1, activation='relu')\n",
    "        self.conv2 = Conv2D(filters=self.d_filt, kernel_size=1)\n",
    "        self.norm2 = LayerNormalization(epsilon=0.0001)\n",
    "        \n",
    "    \n",
    "    def call(self, input):\n",
    "        res = input[0]\n",
    "        \n",
    "        #Attention\n",
    "        x = self.multi_head(input)\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm1(x + res)\n",
    "        \n",
    "        #Feed-forward\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x + res)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [14:04<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "def retrieve_data(data_size):\n",
    "    frames = []\n",
    "\n",
    "    for d in trange(data_size):\n",
    "        video = dataset.update().resolve()\n",
    "        for frame in video:\n",
    "            frames.append(frame)\n",
    "\n",
    "    return tf.stack(frames)\n",
    "\n",
    "data_size = 1000\n",
    "\n",
    "# Save the data\n",
    "data = retrieve_data(data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('video_data.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load if data is already generated\n",
    "data = np.load('video_data.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = len(data)\n",
    "train_size = int(num_frames * 0.8)\n",
    "val_size = num_frames - train_size\n",
    "\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:]\n",
    "\n",
    "max_val = tf.reduce_max(tf.concat([train_data, val_data], axis=0))\n",
    "train_data /= max_val\n",
    "val_data /= max_val\n",
    "\n",
    "print(\"Training data size:\", train_data.shape)\n",
    "print(\"Validation data size:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D=keras.layers.Conv2D\n",
    "MaxPool2D=keras.layers.MaxPooling2D\n",
    "Dense=keras.layers.Dense\n",
    "Flatten=keras.layers.Flatten\n",
    "Reshape=keras.layers.Reshape\n",
    "Input = keras.layers.Input\n",
    "Sequential = keras.Sequential\n",
    "Conv2DTranspose = keras.layers.Conv2DTranspose\n",
    "\n",
    "k_size = 4\n",
    "n_filters = 4\n",
    "bottleneck_size = k_size**2*n_filters\n",
    "\n",
    "class AutoEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = Sequential([\n",
    "            Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1)),\n",
    "            Conv2D(64, (4, 4), activation='relu', padding='same', strides=4),\n",
    "            Conv2D(n_filters, (k_size, k_size), activation='relu', padding='same', strides=4),\n",
    "            Flatten()\n",
    "            ])\n",
    "        \n",
    "        bottleneck_size = k_size**2*n_filters\n",
    "        self.decoder = Sequential([\n",
    "            Input(shape=(bottleneck_size,)),\n",
    "            Reshape(target_shape=(4, 4, n_filters)),\n",
    "            Conv2DTranspose(n_filters, (4, 4), strides=(4, 4), activation='relu', padding='same'),\n",
    "            Conv2DTranspose(64, (8, 8), strides=(4, 4), activation='relu', padding='same'),\n",
    "            Conv2D(1, (1, 1), activation='linear', padding='same')\n",
    "            ])\n",
    "    def call(self, input):\n",
    "        x = self.encoder(input)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "autoencoder = AutoEncoder()\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "autoencoder.encoder.build(input_shape=(None, 64, 64, 1))\n",
    "autoencoder.encoder.summary()\n",
    "\n",
    "autoencoder.decoder.build(input_shape=(None, bottleneck_size))\n",
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(train_data, train_data,\n",
    "                epochs=40,\n",
    "                shuffle=True,\n",
    "                validation_data=(val_data, val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('autoencoder_bottleneck_size='+str(bottleneck_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hwc_venv",
   "language": "python",
   "name": "hwc_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
